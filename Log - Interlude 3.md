
I worked with a lot of different elements in class that were unrelated to my Unessay such as sonification (via [TwoTone (twotone-midiout-beta.netlify.app)](https://twotone-midiout-beta.netlify.app/)and "raising the dead" by making custom AI-Generated Text With GPT-2 with the help of Max Woolfe's blog and [Colaboratory Notebook](https://colab.research.google.com/drive/1VLG8e7YSEwypxU-noRNhsv5dW4NfTGce)in class. I uploaded my text file (Great Expectations - should have been a piece of writing from a historical figure from The Gutengurg Project but I misunderstood) and ran different cells that trained the AI with the new text input. While there was not enough class time to interact with the tool in the **Generate Text From The Trained Model** section with my retrained model, I watched Professor Graham ask the generator different questions in class. Some of the responses were illogical but funny, which revealed some of the limitations of using a singular dataset. 
I also tried Two Tone to generate sound from a dataset using different instruments from a piano and mandolin to a church organ and a glockenspiel. I didn't pursue this further, but was very interested in how sonifying archival archaeological imagery changes the way we look at photography. This sort of image analysis is what I did in analysized AI-generated images for strong and weak patterns in my Unessay research, just as Professor Graham suggested in an email. Just like our eyes, our ears can be trained "to detect, patterns that will in turn enable us to see/understand hidden similarities between photos of a particular era, or constructed towards a particular goal.
My reflection delves into the research I have done for my Unessay but I discovered a project called  "Exploring 12 Million of the 2.3 Billion Images Used to Train Stable Diffusion’s Image Generator." I used the following browser that was created with 12 million sourced images that train OpenAI's DALL-E art generator. I typed in "Indigenous" and ''Native American," "Totem Poles" and "Native American Headdress" into the image finder and also followed this up with a web search of the image to see which sites these images came from. As mentioned in my reflection, many of these were retail sites selling imitation Native American and Indigenous cultural objects for profit. 
I also played with Bitsy to create an avatar, sprite, and a mini virtual world. I had some trouble creating exits and endings in the game but used the following in-game tutorial to get me started: [SHIMMERWITCH.SPACE](https://www.shimmerwitch.space/bitsyTutorial.html)
I also checked out and started a few games from AI Dungeon such as Fiomar and Kringle. These were more fantasy games than historically based, but I enjoyed being able to create my own storyline. However, the AI-generated responses took a while which made gameplay a time consuming process. 